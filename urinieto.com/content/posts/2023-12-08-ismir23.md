---
title: "The Best of ISMIR 2023"
author: uri
type: post
date: 2023-12-08T13:01:29+03:00
url: best-of-ismir23
draft: false
thumbnail:
  src: "/wp-content/uploads/2023/ismir23.png"
  alt: The Duomo of Milan
categories:
  - conferences
  - ISMIR

---

[ISMIR](https://ismir2023.ismir.net/) is back in full swing with over 400 registrations, most of them in-person attendees in the beautiful city of Milan.
Once again, ISMIR proves that it is home to the most incredible research community I've witnessed, and I feel so lucky to be part of it.

{{< img src="/wp-content/uploads/2023/ismir23.png" alt="" width="600" >}}

Overall, this year's conversation had significantly shifted from last year's.
**Generative AI** was, unsurprisingly, the hottest topic, and that lead to several interesting discussions on **ethics** and the fair usage of training data.
This is particularly interesting under the music domain, where training data are typically audio tracks that artists have not necessarily given their consent to be used to train ML models with.
Given how the vast majority of artists struggle to make enough money to sustain their lives, there might be something potentially interesting in how research institutions could license some of their music so that artists get more rewarded.

Additionally, there were several interesting approaches in the **symbolic domain**, which differs from the trend of past ISMIRs where audio-based approaches tended to dominate.

It's hard to pick the best papers, but here's my personal top 10.
Here we go, titans!

# Best 10 Papers

### [VampNet: Music Generation Via Masked Acoustic Token Modeling - Flores GarcÃ­a  et al.](https://archives.ismir.net/ismir2023/paper/000042.pdf)

What a fantastic usage of discrete tokens for music generation. Not only the approach is highly interesting, where one can condition the model to inpaint, to change timbre, rhythm, finish/start songs, etc., but the paper comes with a fantastically written open source [implementation](https://github.com/hugofloresgarcia/vampnet), a Max patch [plugin](https://github.com/hugofloresgarcia/unloop), and several incredible [examples](https://hugo-does-things.notion.site/VampNet-Music-Generation-via-Masked-Acoustic-Token-Modeling-e37aabd0d5f1493aa42c5711d0764b33). On top of all of this, Hugo and Bryan gave a fun performance using VampNet during the music program!

### [Data Collection In Music Generation Training Sets: A Critical Analysis - Pereira et al.](https://archives.ismir.net/ismir2023/paper/000003.pdf)

This paper brings up highly relevant questions in today's generative AI world where ethically-soruced data are key: do dataset creators have the artists' consent to use their content for genAI purposes? Did the dataset curators hire musicians / license their music to put together such datasets? Unsurprisingly, the results after investigating over a hundred datasets used in ISMIR throughout the years show that most datasets were gathered by scraping the Internets, without asking for any consent to the original artists.
So happy to see that this type of research is finally making a big splash in the ISMIR community.
This work won the **best paper Universal Music Group award** (kind of ironically, given how much the music industry has historically underpaid the actual musicians).

### [Towards Building A Phylogeny Of Gregorian Chant Melodies - Hajic jr et al.](https://archives.ismir.net/ismir2023/paper/000067.pdf)

I truly loved this one. The authors applied phylogeny (i.e., the analysis of the evolution of protein of nucleo-acid sequences) to gregorian chant melodies.
This allows to understand the small differences that were introduced in such melodies throughout the centuries. 
They link their findings with the belief systems that the different monks/sects had around that time. Certain fractions believed that chants had to be extensively reviewed as it was requested by _higher powers_, while others were more laxed about it.
The latter group shows how their melodies added much more variation across several decades.

### [MoisesDB: A Dataset For Source Separation Beyond 4-Stems - Morreale et al.](https://archives.ismir.net/ismir2023/paper/000073.pdf)

A dataset with stems curated _and recorded_ specifically for this purpose.
240 new tracks that represent a total of 14 hours of music.
The dataset is offered free of charge for non-commercial purposes.
The way to go to curate and release datasets, good job Moises.AI!
You can download it from their [research site](https://music.ai/research/).

### [PESTO: Pitch Estimation With Self-supervised Transposition-equivariant Objective - Riou et al.](https://archives.ismir.net/ismir2023/paper/000063.pdf)

Completely self-supervised method for Pitch Estimation (i.e., no labeled data are required for training).
To do so, they transpose the signal and feed both versions to their model to estimate the pitches.
They model it as a classification problem, and they use both probability densities (the output of the model) to come up with a new loss to minimize the differences between the two versions of the signal.
They train it in a siamese manner to minimize this new "Transposition Equivariant" loss, and they yield results that are very close to SOTA (ie, CREPE), _but without using any labeled data_. Very impressive!
Winner of the **best paper award** ðŸŽ‰.





# Conclusion

ISMIR is home to such an incredibly talented set of researchers.
One of the things I truly love about this community is its passionate and collaborative nature.
As opposed to other huge communities like Computer Vision, general Machine Learning, or Audio Processing, there is no apparent _hierarchy_ at ISMIR.
Big names in the field talk to newcomers in a completely flat manner, which helps in terms of making everyone feel included and considered.
On top of all of that, it is apparent our pure love for music, which surfaces on every aspect of the conference: from the keynotes (which were, the three of them, extremely good!) to the music program passing through the satellite events and the serendipitious conversations with the attendees.
Watching some of the biggest names in the field playing their instruments masterfully along with one of the keynote speakers during the jam session was pretty mindblowing and inspiring!

Despite one of the two General Chairs (Augusto TODO) having had a serious health issue, and Fabio TODO being a newcomer to the community, this has been an incredible ISMIR.
Everything ran really smoothly, from the banquet to the sessions, passing through the jam session!
A word on that: some of us were a bit worried that there was not a lot of information about the ISMIR jam session this year (or rather, the available information was very different from what the ISMIR community is used to).
So the community stepped up and, after awesome performances with Mark d'Inverno and Joey Stuckey (TODO), Matthias Mauch ended up leading a really fun jam session where I had the pleasure to [scream]() for a little bit :)

Overall, congratulations to the organizers, volunteers, authors, and all participants for making this ISMIR 2023 an unforgettable one.
Hope to see you all in San Francisco next year!

